{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3323625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional, Set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a145ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATHS = {\n",
    "    \"DoS\":   \"../../Dataset/DoS_dataset_clean.csv\",\n",
    "    \"Fuzzy\": \"../../Dataset/Fuzzy_dataset_clean.csv\",\n",
    "    \"Gear\":  \"../../Dataset/gear_dataset_clean.csv\",\n",
    "    \"RPM\":   \"../../Dataset/RPM_dataset_clean.csv\",\n",
    "}\n",
    "\n",
    "WINDOW_SIZE = 200\n",
    "WINDOW_STRIDE = 200\n",
    "SAMPLE_RATIO = 0.10\n",
    "MCQS_PER_WINDOW = 3\n",
    "GLOBAL_SEED = 50\n",
    "\n",
    "BYTE_COLUMNS = [f\"Byte{i}\" for i in range(1, 9)]\n",
    "ATTACK_LABELS = [\"DoS\", \"Fuzzy\", \"Gear\", \"RPM\"]\n",
    "SUPPRESSION_THRESHOLD = 1e-3\n",
    "FLOODING_THRESHOLD = 5e-4\n",
    "\n",
    "\n",
    "SELECTED_DATASETS = [\"DoS\", \"Fuzzy\", \"Gear\", \"RPM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded DoS: 3665771 rows, 5 expected IDs, 3 critical IDs.\n",
      "[INFO] Loaded Fuzzy: 3838860 rows, 5 expected IDs, 3 critical IDs.\n",
      "[INFO] Loaded Gear: 4443142 rows, 5 expected IDs, 3 critical IDs.\n",
      "[INFO] Loaded RPM: 4621702 rows, 5 expected IDs, 3 critical IDs.\n"
     ]
    }
   ],
   "source": [
    "def _normalize_flag_series(series: pd.Series) -> pd.Series:\n",
    "    mapped = series.map({\"R\": 0, \"T\": 1})\n",
    "    numeric = pd.to_numeric(series, errors=\"coerce\")\n",
    "    combined = mapped.fillna(numeric).fillna(0).astype(int)\n",
    "    return combined\n",
    "\n",
    "\n",
    "def load_datasets(paths: Dict[str, str]):\n",
    "    datasets: Dict[str, pd.DataFrame] = {}\n",
    "    profiles: Dict[str, dict] = {}\n",
    "\n",
    "    for name, path in paths.items():\n",
    "        csv_path = Path(path)\n",
    "        if not csv_path.exists():\n",
    "            print(f\"[WARN] Dataset {name} not found at {csv_path}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if \"Flag\" in df.columns:\n",
    "            df[\"Flag\"] = _normalize_flag_series(df[\"Flag\"])\n",
    "        else:\n",
    "            df[\"Flag\"] = 0\n",
    "\n",
    "        id_counts = df[\"ID\"].value_counts()\n",
    "        expected_ids = set(int(x) for x in id_counts.head(5).index.tolist())\n",
    "        critical_ids = set(int(x) for x in id_counts.head(3).index.tolist())\n",
    "\n",
    "        datasets[name] = df\n",
    "        profiles[name] = {\n",
    "            \"expected_ids\": expected_ids,\n",
    "            \"critical_ids\": critical_ids,\n",
    "            \"attack_label\": name,\n",
    "        }\n",
    "\n",
    "        print(f\"[INFO] Loaded {name}: {len(df)} rows, \"\n",
    "              f\"{len(expected_ids)} expected IDs, {len(critical_ids)} critical IDs.\")\n",
    "\n",
    "    return datasets, profiles\n",
    "\n",
    "\n",
    "datasets, profiles = load_datasets({k: v for k, v in DATASET_PATHS.items() if k in SELECTED_DATASETS})\n",
    "rng_global = np.random.default_rng(GLOBAL_SEED)\n",
    "\n",
    "\n",
    "# Cell 3: helpers (window, stats)\n",
    "def iter_window_starts(num_rows: int) -> List[int]:\n",
    "    if num_rows < WINDOW_SIZE:\n",
    "        return []\n",
    "    return list(range(0, num_rows - WINDOW_SIZE + 1, WINDOW_STRIDE))\n",
    "\n",
    "\n",
    "def sample_window_indices(starts: List[int], rng: np.random.Generator) -> List[int]:\n",
    "    if not starts:\n",
    "        return []\n",
    "    sample_size = max(1, int(len(starts) * SAMPLE_RATIO))\n",
    "    sample_size = min(sample_size, len(starts))\n",
    "    return sorted(rng.choice(starts, size=sample_size, replace=False))\n",
    "\n",
    "\n",
    "def format_window(df: pd.DataFrame) -> str:\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        byte_vals = [int(row[col]) for col in BYTE_COLUMNS]\n",
    "        rows.append(\n",
    "            f\"Timestamp={row['Timestamp']:.6f} | \"\n",
    "            f\"ID={int(row['ID'])} | DLC={int(row['DLC'])} | \"\n",
    "            f\"bytes={byte_vals} | Flag={int(row['Flag'])} |\"\n",
    "        )\n",
    "    return \"\\n\".join(rows)\n",
    "\n",
    "\n",
    "def compute_basic_stats(df: pd.DataFrame) -> dict:\n",
    "    stats = {}\n",
    "    total_frames = len(df)\n",
    "    if total_frames == 0:\n",
    "        return stats\n",
    "\n",
    "    id_counts = df[\"ID\"].value_counts()\n",
    "    stats[\"id_counts\"] = id_counts\n",
    "    stats[\"dominant_id\"] = int(id_counts.index[0])\n",
    "    stats[\"dominant_share\"] = id_counts.iloc[0] / total_frames\n",
    "\n",
    "    # timing\n",
    "    if total_frames > 1:\n",
    "        diffs = df[\"Timestamp\"].to_numpy()[1:] - df[\"Timestamp\"].to_numpy()[:-1]\n",
    "        stats[\"diffs\"] = diffs\n",
    "        stats[\"gap_max\"] = float(diffs.max())\n",
    "        stats[\"gap_min\"] = float(diffs.min())\n",
    "        stats[\"gap_mean\"] = float(diffs.mean())\n",
    "        stats[\"gap_std\"] = float(diffs.std())\n",
    "        stats[\"window_duration\"] = float(df[\"Timestamp\"].iloc[-1] - df[\"Timestamp\"].iloc[0])\n",
    "    else:\n",
    "        stats[\"diffs\"] = np.array([])\n",
    "        stats[\"gap_max\"] = 0.0\n",
    "        stats[\"gap_min\"] = 0.0\n",
    "        stats[\"gap_mean\"] = 0.0\n",
    "        stats[\"gap_std\"] = 0.0\n",
    "        stats[\"window_duration\"] = 0.0\n",
    "\n",
    "    # payload const for dominant id\n",
    "    dom_group = df[df[\"ID\"] == stats[\"dominant_id\"]]\n",
    "    if not dom_group.empty:\n",
    "        payload = dom_group[BYTE_COLUMNS].to_numpy()\n",
    "        stats[\"dominant_payload_var\"] = float(payload.var())\n",
    "    else:\n",
    "        stats[\"dominant_payload_var\"] = 0.0\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "# Cell 4: MCQ generation (a few template types)\n",
    "def generate_mcq_attack_type(stats: dict, profile: dict, rng: np.random.Generator) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Attack-type MCQ:\n",
    "    Question: which attack type best fits this window?\n",
    "    Options: 4 labels from ATTACK_LABELS.\n",
    "    Ground truth: profile['attack_label'].\n",
    "    \"\"\"\n",
    "    gt_label = profile.get(\"attack_label\", \"DoS\")\n",
    "    distractors = [x for x in ATTACK_LABELS if x != gt_label]\n",
    "    if len(distractors) < 3:\n",
    "        return None\n",
    "    chosen_distractors = list(rng.choice(distractors, size=3, replace=False))\n",
    "    labels = [gt_label] + chosen_distractors\n",
    "    rng.shuffle(labels)\n",
    "\n",
    "    label_to_text = {\n",
    "        \"DoS\":   \"Flooding / DoS-like behavior\",\n",
    "        \"Fuzzy\": \"Fuzzy ID injection with many unseen IDs\",\n",
    "        \"Gear\":  \"Gear spoofing affecting transmission or drive state\",\n",
    "        \"RPM\":   \"RPM spoofing affecting engine speed readings\",\n",
    "    }\n",
    "    options_text = [label_to_text[l] for l in labels]\n",
    "    correct_index = labels.index(gt_label)\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    options = {letters[i]: options_text[i] for i in range(4)}\n",
    "    answer = letters[correct_index]\n",
    "\n",
    "    return {\n",
    "        \"type\": \"attack_type\",\n",
    "        \"question\": \"Which attack type best fits the behavior in this window?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": answer,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_dominant_id(df: pd.DataFrame, stats: dict, rng: np.random.Generator) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    ID frequency MCQ:\n",
    "    Question: which CAN ID appears most frequently in this window?\n",
    "    \"\"\"\n",
    "    id_counts = stats.get(\"id_counts\")\n",
    "    if id_counts is None or id_counts.empty:\n",
    "        return None\n",
    "\n",
    "    top_ids = list(id_counts.index[:4])\n",
    "    if len(top_ids) < 2:\n",
    "        return None\n",
    "\n",
    "    if len(top_ids) < 4:\n",
    "        other_ids = [int(i) for i in df[\"ID\"].unique() if int(i) not in top_ids]\n",
    "        rng.shuffle(other_ids)\n",
    "        top_ids = top_ids + other_ids[: max(0, 4 - len(top_ids))]\n",
    "        top_ids = top_ids[:4]\n",
    "\n",
    "    dom_id = stats[\"dominant_id\"]\n",
    "    if dom_id not in top_ids:\n",
    "        top_ids[0] = dom_id\n",
    "\n",
    "    rng.shuffle(top_ids)\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    options = {}\n",
    "    correct_index = None\n",
    "    for i, id_val in enumerate(top_ids):\n",
    "        options[letters[i]] = f\"ID 0x{int(id_val):03X}\"\n",
    "        if int(id_val) == dom_id:\n",
    "            correct_index = i\n",
    "    if correct_index is None:\n",
    "        return None\n",
    "    answer = letters[correct_index]\n",
    "\n",
    "    return {\n",
    "        \"type\": \"dominant_id\",\n",
    "        \"question\": \"Which CAN ID appears most frequently in this window?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": answer,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_timing(stats: dict) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Timing behavior MCQ:\n",
    "    \"\"\"\n",
    "    diffs = stats.get(\"diffs\", np.array([]))\n",
    "    if diffs.size == 0:\n",
    "        return None\n",
    "\n",
    "    gap_max = stats[\"gap_max\"]\n",
    "    gap_std = stats[\"gap_std\"]\n",
    "\n",
    "    # A: suppression (large gaps)\n",
    "    # B: flooding (extremely small gaps & low variance)\n",
    "    # C: uniform timing\n",
    "    # D: random timing\n",
    "    if gap_max > SUPPRESSION_THRESHOLD * 5:\n",
    "        correct = \"A\"\n",
    "    elif stats[\"gap_mean\"] < FLOODING_THRESHOLD and gap_std < FLOODING_THRESHOLD:\n",
    "        correct = \"B\"\n",
    "    elif gap_std < stats[\"gap_mean\"] * 0.1:\n",
    "        correct = \"C\"\n",
    "    else:\n",
    "        correct = \"D\"\n",
    "\n",
    "    options = {\n",
    "        \"A\": \"Several large gaps suggest suppression behavior.\",\n",
    "        \"B\": \"Extremely small gaps suggest flooding.\",\n",
    "        \"C\": \"Timing is mostly uniform with minor jitter.\",\n",
    "        \"D\": \"Timing is random with no clear pattern.\",\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"type\": \"timing\",\n",
    "        \"question\": \"Which description best matches the timing behavior in this window?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def generate_mcq_abnormal_rate_id(stats: dict, rng: np.random.Generator) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q2/Q18 Which CAN ID shows an abnormal increase in transmission rate?\n",
    "    \"\"\"\n",
    "    id_counts = stats.get(\"id_counts\")\n",
    "    if id_counts is None or id_counts.empty:\n",
    "        return None\n",
    "    total = id_counts.sum()\n",
    "    dom_id = stats[\"dominant_id\"]\n",
    "    dom_share = stats[\"dominant_share\"]\n",
    "\n",
    "    threshold = 0.5\n",
    "    if dom_share > threshold:\n",
    "        gt = \"abnormal\"\n",
    "    else:\n",
    "        gt = \"none\"\n",
    "\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    candidate_ids = list(id_counts.index[:4])\n",
    "    if dom_id not in candidate_ids:\n",
    "        candidate_ids.insert(0, dom_id)\n",
    "    candidate_ids = [int(x) for x in candidate_ids[:3]]\n",
    "\n",
    "    options = {}\n",
    "    correct_letter = None\n",
    "    idx = 0\n",
    "    if gt == \"abnormal\":\n",
    "        options[letters[idx]] = f\"ID 0x{dom_id:03X}\"\n",
    "        correct_letter = letters[idx]\n",
    "        idx += 1\n",
    "        for cid in candidate_ids:\n",
    "            if cid == dom_id:\n",
    "                continue\n",
    "            if idx >= 3:\n",
    "                break\n",
    "            options[letters[idx]] = f\"ID 0x{cid:03X}\"\n",
    "            idx += 1\n",
    "        options[letters[idx]] = \"No ID shows abnormal frequency\"\n",
    "    else:\n",
    "        options[letters[idx]] = \"No ID shows abnormal frequency\"\n",
    "        correct_letter = letters[idx]\n",
    "        idx += 1\n",
    "        for cid in candidate_ids:\n",
    "            if idx >= 4:\n",
    "                break\n",
    "            options[letters[idx]] = f\"ID 0x{cid:03X}\"\n",
    "            idx += 1\n",
    "\n",
    "    if correct_letter is None or len(options) < 2:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"type\": \"id_abnormal_rate\",\n",
    "        \"question\": \"Which CAN ID shows an abnormal increase in transmission rate?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct_letter,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_missing_expected_id(df: pd.DataFrame, profile: dict,\n",
    "                                     rng: np.random.Generator) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q3/Q21 Which ID is missing compared to expected control IDs?\n",
    "    \"\"\"\n",
    "    expected_ids: Set[int] = profile.get(\"expected_ids\", set())\n",
    "    if not expected_ids:\n",
    "        return None\n",
    "\n",
    "    present_ids = set(int(x) for x in df[\"ID\"].unique())\n",
    "    missing = [eid for eid in expected_ids if eid not in present_ids]\n",
    "\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    options = {}\n",
    "    correct_letter = None\n",
    "\n",
    "    if missing:\n",
    "\n",
    "        correct_id = rng.choice(missing)\n",
    "        options[letters[0]] = f\"ID 0x{correct_id:03X}\"\n",
    "        correct_letter = letters[0]\n",
    "\n",
    "        present_expected = [eid for eid in expected_ids if eid in present_ids and eid != correct_id]\n",
    "        rng.shuffle(present_expected)\n",
    "        idx = 1\n",
    "        for eid in present_expected[:2]:\n",
    "            options[letters[idx]] = f\"ID 0x{eid:03X}\"\n",
    "            idx += 1\n",
    "        options[letters[idx]] = \"None is missing\"\n",
    "    else:\n",
    "        options[letters[0]] = \"None is missing\"\n",
    "        correct_letter = letters[0]\n",
    "        present_expected = list(expected_ids)\n",
    "        rng.shuffle(present_expected)\n",
    "        idx = 1\n",
    "        for eid in present_expected[:3]:\n",
    "            options[letters[idx]] = f\"ID 0x{eid:03X}\"\n",
    "            idx += 1\n",
    "\n",
    "    return {\n",
    "        \"type\": \"expected_id_missing\",\n",
    "        \"question\": \"Which ID is missing compared to expected control IDs?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct_letter,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_constant_payload_id(df: pd.DataFrame,\n",
    "                                     rng: np.random.Generator) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q10 Which ID shows an unusually constant payload?\n",
    "    \"\"\"\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    options = {}\n",
    "    candidate_ids = []\n",
    "\n",
    "    for id_val, group in df.groupby(\"ID\"):\n",
    "        if len(group) < 3:\n",
    "            continue\n",
    "        payload = group[BYTE_COLUMNS].to_numpy()\n",
    "        var = payload.var()\n",
    "        if var < 1e-3:\n",
    "            candidate_ids.append(int(id_val))\n",
    "\n",
    "    if not candidate_ids:\n",
    "        options[letters[0]] = \"None shows constant payload\"\n",
    "        correct_letter = letters[0]\n",
    "        ids = list(int(x) for x in df[\"ID\"].unique())\n",
    "        rng.shuffle(ids)\n",
    "        idx = 1\n",
    "        for id_val in ids[:3]:\n",
    "            options[letters[idx]] = f\"ID 0x{id_val:03X}\"\n",
    "            idx += 1\n",
    "    else:\n",
    "        correct_id = rng.choice(candidate_ids)\n",
    "        options[letters[0]] = f\"ID 0x{correct_id:03X}\"\n",
    "        correct_letter = letters[0]\n",
    "        other_ids = [int(x) for x in df[\"ID\"].unique() if int(x) != correct_id]\n",
    "        rng.shuffle(other_ids)\n",
    "        idx = 1\n",
    "        for id_val in other_ids[:2]:\n",
    "            options[letters[idx]] = f\"ID 0x{id_val:03X}\"\n",
    "            idx += 1\n",
    "        options[letters[idx]] = \"None shows constant payload\"\n",
    "\n",
    "    return {\n",
    "        \"type\": \"constant_payload_id\",\n",
    "        \"question\": \"Which ID shows an unusually constant payload?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct_letter,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_payload_pattern(stats: dict) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q11 Which phenomenon best describes the payload pattern?\n",
    "    \"\"\"\n",
    "    var = stats.get(\"dominant_payload_var\", 0.0)\n",
    "\n",
    "    if var < 1e-3:\n",
    "        correct = \"A\"  # Several IDs transmit identical payloads repeatedly\n",
    "    elif var < 1.0:\n",
    "        correct = \"B\"  # Payload values increase steadily\n",
    "    else:\n",
    "        correct = \"C\"  # Payload varies unpredictably\n",
    "\n",
    "    options = {\n",
    "        \"A\": \"Several IDs transmit identical payloads repeatedly.\",\n",
    "        \"B\": \"Payload values increase steadily.\",\n",
    "        \"C\": \"Payload varies unpredictably.\",\n",
    "        \"D\": \"Most payloads are near zero.\",\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"type\": \"payload_pattern\",\n",
    "        \"question\": \"Which phenomenon best describes the payload pattern?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_dlc_distribution(df: pd.DataFrame) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q14 Which statement best describes DLC distribution?\n",
    "    \"\"\"\n",
    "    dlc = df[\"DLC\"].to_numpy()\n",
    "    if dlc.size == 0:\n",
    "        return None\n",
    "    share_8 = (dlc == 8).mean()\n",
    "    share_low = (dlc <= 4).mean()\n",
    "\n",
    "    if share_8 > 0.6:\n",
    "        correct = \"A\"\n",
    "    elif share_low > 0.6:\n",
    "        correct = \"C\"\n",
    "    else:\n",
    "        correct = \"B\"\n",
    "\n",
    "    options = {\n",
    "        \"A\": \"Majority of frames have DLC = 8.\",\n",
    "        \"B\": \"DLC values vary evenly.\",\n",
    "        \"C\": \"DLC is consistently low.\",\n",
    "        \"D\": \"DLC appears corrupted.\",\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"type\": \"dlc_distribution\",\n",
    "        \"question\": \"Which statement best describes DLC distribution?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_flag_behavior(df: pd.DataFrame) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q24 What best describes flag behavior in this window?\n",
    "    \"\"\"\n",
    "    flags = df[\"Flag\"].to_numpy()\n",
    "    if flags.size == 0:\n",
    "        return None\n",
    "    unique_flags = np.unique(flags)\n",
    "\n",
    "    if len(unique_flags) == 1:\n",
    "        correct = \"A\"  # All flags are identical\n",
    "    elif len(unique_flags) == 2 and all(v in [0, 1] for v in unique_flags):\n",
    "        correct = \"B\"  # Both flag values (0/1) appear frequently\n",
    "    else:\n",
    "        correct = \"C\"\n",
    "\n",
    "    options = {\n",
    "        \"A\": \"All flags are identical.\",\n",
    "        \"B\": \"Both flag values (0/1) appear frequently.\",\n",
    "        \"C\": \"Flags are inconsistent and likely corrupted.\",\n",
    "        \"D\": \"Several flags appear missing.\",\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"type\": \"flag_behavior\",\n",
    "        \"question\": \"What best describes flag behavior in this window?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_overall_window(stats: dict) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q30 How would you best characterize this window overall?\n",
    "    \"\"\"\n",
    "    dom_share = stats.get(\"dominant_share\", 0.0)\n",
    "    gap_std = stats.get(\"gap_std\", 0.0)\n",
    "\n",
    "    if dom_share > 0.7 and gap_std < FLOODING_THRESHOLD:\n",
    "        correct = \"B\"  # Highly irregular and unsafe\n",
    "    elif dom_share < 0.4 and gap_std < stats.get(\"gap_mean\", 1.0) * 0.1:\n",
    "        correct = \"C\"  # Uniform and typical\n",
    "    else:\n",
    "        correct = \"A\"  # Mostly stable with minor anomalies\n",
    "\n",
    "    options = {\n",
    "        \"A\": \"Mostly stable with minor anomalies.\",\n",
    "        \"B\": \"Highly irregular and unsafe.\",\n",
    "        \"C\": \"Uniform and typical.\",\n",
    "        \"D\": \"Largely empty or incomplete.\",\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"type\": \"overall_window\",\n",
    "        \"question\": \"How would you best characterize this window overall?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_id_most_irregular_timing(df: pd.DataFrame,\n",
    "                                          rng: np.random.Generator) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q4 / Q4 \n",
    "    Which ID shows the most irregular timing pattern?\n",
    "    \"\"\"\n",
    "    gaps_std = {}\n",
    "    for id_val, group in df.groupby(\"ID\"):\n",
    "        ts = group[\"Timestamp\"].to_numpy()\n",
    "        if ts.size < 3:\n",
    "            continue\n",
    "        diffs = np.diff(ts)\n",
    "        if diffs.size == 0:\n",
    "            continue\n",
    "        gaps_std[int(id_val)] = float(diffs.std())\n",
    "\n",
    "    if not gaps_std:\n",
    "        return None\n",
    "\n",
    "    sorted_ids = sorted(gaps_std.items(), key=lambda x: x[1], reverse=True)\n",
    "    correct_id = sorted_ids[0][0]\n",
    "\n",
    "    other_ids = [id_ for id_, _ in sorted_ids[1:]]\n",
    "    ids_for_options = [correct_id]\n",
    "    rng.shuffle(other_ids)\n",
    "    ids_for_options.extend(other_ids[:3])\n",
    "    ids_for_options = ids_for_options[:4]\n",
    "    rng.shuffle(ids_for_options)\n",
    "\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    options = {}\n",
    "    correct_letter = None\n",
    "    for i, id_val in enumerate(ids_for_options):\n",
    "        options[letters[i]] = f\"ID 0x{id_val:03X}\"\n",
    "        if id_val == correct_id:\n",
    "            correct_letter = letters[i]\n",
    "\n",
    "    if correct_letter is None:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"type\": \"id_irregular_timing\",\n",
    "        \"question\": \"Which CAN ID shows the most irregular timing pattern?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct_letter,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_id_shortest_gap(df: pd.DataFrame,\n",
    "                                 rng: np.random.Generator) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q7 \n",
    "    Which ID shows the shortest average inter-frame gap?\n",
    "    \"\"\"\n",
    "    gaps_mean = {}\n",
    "    for id_val, group in df.groupby(\"ID\"):\n",
    "        ts = group[\"Timestamp\"].to_numpy()\n",
    "        if ts.size < 3:\n",
    "            continue\n",
    "        diffs = np.diff(ts)\n",
    "        if diffs.size == 0:\n",
    "            continue\n",
    "        gaps_mean[int(id_val)] = float(diffs.mean())\n",
    "\n",
    "    if not gaps_mean:\n",
    "        return None\n",
    "\n",
    "    sorted_ids = sorted(gaps_mean.items(), key=lambda x: x[1])\n",
    "    correct_id = sorted_ids[0][0]\n",
    "\n",
    "    other_ids = [id_ for id_, _ in sorted_ids[1:]]\n",
    "    ids_for_options = [correct_id]\n",
    "    rng.shuffle(other_ids)\n",
    "    ids_for_options.extend(other_ids[:3])\n",
    "    ids_for_options = ids_for_options[:4]\n",
    "    rng.shuffle(ids_for_options)\n",
    "\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    options = {}\n",
    "    correct_letter = None\n",
    "    for i, id_val in enumerate(ids_for_options):\n",
    "        options[letters[i]] = f\"ID 0x{id_val:03X}\"\n",
    "        if id_val == correct_id:\n",
    "            correct_letter = letters[i]\n",
    "\n",
    "    if correct_letter is None:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"type\": \"id_shortest_gap\",\n",
    "        \"question\": \"Which CAN ID shows the shortest average inter-frame gap?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct_letter,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_window_duration(stats: dict) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q8 \n",
    "    What best describes the time coverage of this window?\n",
    "    \"\"\"\n",
    "    duration = stats.get(\"window_duration\", 0.0)\n",
    "    if duration <= 0:\n",
    "        return None\n",
    "\n",
    "    if duration > 0.5:\n",
    "        correct = \"A\"  # unusually long\n",
    "    elif duration < 0.05:\n",
    "        correct = \"C\"  # too short\n",
    "    else:\n",
    "        correct = \"B\"  # typical duration\n",
    "\n",
    "    options = {\n",
    "        \"A\": \"The window spans an unusually long duration.\",\n",
    "        \"B\": \"The window spans a typical duration.\",\n",
    "        \"C\": \"The window is too short to analyze.\",\n",
    "        \"D\": \"Time information is inconsistent.\",\n",
    "    }\n",
    "    return {\n",
    "        \"type\": \"window_duration\",\n",
    "        \"question\": \"What best describes the time coverage of this window?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_burst_explanation(stats: dict) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q9/Q19/Q20\n",
    "    What best explains the burst behavior observed?\n",
    "    \"\"\"\n",
    "    dom_share = stats.get(\"dominant_share\", 0.0)\n",
    "    gap_mean = stats.get(\"gap_mean\", 0.0)\n",
    "    gap_std = stats.get(\"gap_std\", 0.0)\n",
    "\n",
    "    if gap_mean < FLOODING_THRESHOLD and dom_share > 0.5:\n",
    "        correct = \"B\"  # Flooding from a compromised ECU\n",
    "    elif gap_mean > SUPPRESSION_THRESHOLD and gap_std > gap_mean * 0.5:\n",
    "        correct = \"C\"  # Diagnostic traffic or recovery\n",
    "    else:\n",
    "        correct = \"A\"  # Normal periodic or mild burst\n",
    "\n",
    "    options = {\n",
    "        \"A\": \"Normal periodic behavior with minor bursts.\",\n",
    "        \"B\": \"Flooding from a compromised ECU.\",\n",
    "        \"C\": \"Diagnostic or recovery traffic causing bursts.\",\n",
    "        \"D\": \"Random logging artifact with no pattern.\",\n",
    "    }\n",
    "    return {\n",
    "        \"type\": \"burst_explanation\",\n",
    "        \"question\": \"What best explains the burst behavior observed in this window?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_high_dlc_id(df: pd.DataFrame,\n",
    "                             rng: np.random.Generator) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q15 \n",
    "    Which ID shows the highest average DLC usage?\n",
    "    \"\"\"\n",
    "    if \"DLC\" not in df.columns:\n",
    "        return None\n",
    "\n",
    "    dlc_mean_by_id = df.groupby(\"ID\")[\"DLC\"].mean()\n",
    "    if dlc_mean_by_id.empty:\n",
    "        return None\n",
    "\n",
    "    correct_id = int(dlc_mean_by_id.idxmax())\n",
    "\n",
    "    other_ids = [int(x) for x in dlc_mean_by_id.index if int(x) != correct_id]\n",
    "    rng.shuffle(other_ids)\n",
    "    ids_for_options = [correct_id] + other_ids[:3]\n",
    "    ids_for_options = ids_for_options[:4]\n",
    "    rng.shuffle(ids_for_options)\n",
    "\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    options = {}\n",
    "    correct_letter = None\n",
    "    for i, id_val in enumerate(ids_for_options):\n",
    "        options[letters[i]] = f\"0x{id_val:03X}\"\n",
    "        if id_val == correct_id:\n",
    "            correct_letter = letters[i]\n",
    "\n",
    "    if correct_letter is None:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"type\": \"high_dlc_id\",\n",
    "        \"question\": \"Which ID shows the highest DLC usage?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct_letter,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_high_dlc_increase(df: pd.DataFrame) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q16 \n",
    "    What does a sudden increase in high-DLC frames suggest?\n",
    "    \"\"\"\n",
    "    if \"DLC\" not in df.columns:\n",
    "        return None\n",
    "    dlc = df[\"DLC\"].to_numpy()\n",
    "    if dlc.size == 0:\n",
    "        return None\n",
    "\n",
    "    high_share = (dlc >= 7).mean()\n",
    "    if high_share > 0.5:\n",
    "        correct = \"B\"  # Injection of crafted frames\n",
    "    else:\n",
    "        correct = \"A\"  # Onboard diagnostics OR normal\n",
    "\n",
    "    options = {\n",
    "        \"A\": \"Onboard diagnostics or normal high-payload traffic.\",\n",
    "        \"B\": \"Injection of crafted frames.\",\n",
    "        \"C\": \"Normal low-rate sensor updates.\",\n",
    "        \"D\": \"Bus-off recovery sequence.\",\n",
    "    }\n",
    "    return {\n",
    "        \"type\": \"high_dlc_increase\",\n",
    "        \"question\": \"What does a sudden increase in high-DLC frames suggest?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_critical_id_abnormal(df: pd.DataFrame,\n",
    "                                      profile: dict,\n",
    "                                      rng: np.random.Generator) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q22 \n",
    "    Which critical ID behaves abnormally?\n",
    "    \"\"\"\n",
    "    critical_ids: Set[int] = profile.get(\"critical_ids\", set())\n",
    "    if not critical_ids:\n",
    "        return None\n",
    "\n",
    "    df_crit = df[df[\"ID\"].isin(critical_ids)]\n",
    "    if df_crit.empty:\n",
    "        return None\n",
    "\n",
    "    id_counts = df_crit[\"ID\"].value_counts()\n",
    "    total = id_counts.sum()\n",
    "    abnormal_scores = {}\n",
    "\n",
    "    for id_val, count in id_counts.items():\n",
    "        freq_score = count / total\n",
    "        flags = df_crit[df_crit[\"ID\"] == id_val][\"Flag\"].to_numpy()\n",
    "        flag_var = float(np.var(flags)) if flags.size > 0 else 0.0\n",
    "        abnormal_scores[int(id_val)] = freq_score + flag_var\n",
    "\n",
    "    if not abnormal_scores:\n",
    "        return None\n",
    "\n",
    "    sorted_ids = sorted(abnormal_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    correct_id = sorted_ids[0][0]\n",
    "\n",
    "    other_ids = [id_ for id_, _ in sorted_ids[1:]]\n",
    "    ids_for_options = [correct_id]\n",
    "    rng.shuffle(other_ids)\n",
    "    ids_for_options.extend(other_ids[:3])\n",
    "    ids_for_options = ids_for_options[:4]\n",
    "    rng.shuffle(ids_for_options)\n",
    "\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    options = {}\n",
    "    correct_letter = None\n",
    "    for i, id_val in enumerate(ids_for_options):\n",
    "        options[letters[i]] = f\"ID 0x{id_val:03X}\"\n",
    "        if id_val == correct_id:\n",
    "            correct_letter = letters[i]\n",
    "\n",
    "    if correct_letter is None:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"type\": \"critical_id_abnormal\",\n",
    "        \"question\": \"Which critical ID behaves abnormally?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct_letter,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_flag_suspicious_id(df: pd.DataFrame,\n",
    "                                    rng: np.random.Generator) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q25 \n",
    "    Which ID's flag pattern appears most suspicious?\n",
    "    \"\"\"\n",
    "    suspicious_scores = {}\n",
    "    for id_val, group in df.groupby(\"ID\"):\n",
    "        flags = group[\"Flag\"].to_numpy()\n",
    "        if flags.size < 3:\n",
    "            continue\n",
    "        switches = np.sum(flags[1:] != flags[:-1])\n",
    "        unique = np.unique(flags)\n",
    "        if len(unique) == 1:\n",
    "            score = 0.0 \n",
    "        else:\n",
    "            score = switches / (flags.size - 1)\n",
    "        suspicious_scores[int(id_val)] = score\n",
    "\n",
    "    if not suspicious_scores:\n",
    "        return None\n",
    "\n",
    "    sorted_ids = sorted(suspicious_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    correct_id = sorted_ids[0][0]\n",
    "\n",
    "    other_ids = [id_ for id_, _ in sorted_ids[1:]]\n",
    "    ids_for_options = [correct_id]\n",
    "    rng.shuffle(other_ids)\n",
    "    ids_for_options.extend(other_ids[:3])\n",
    "    ids_for_options = ids_for_options[:4]\n",
    "    rng.shuffle(ids_for_options)\n",
    "\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    options = {}\n",
    "    correct_letter = None\n",
    "    for i, id_val in enumerate(ids_for_options):\n",
    "        options[letters[i]] = f\"ID with flag pattern on 0x{id_val:03X}\"\n",
    "        if id_val == correct_id:\n",
    "            correct_letter = letters[i]\n",
    "\n",
    "    if correct_letter is None:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"type\": \"flag_suspicious_id\",\n",
    "        \"question\": \"Which ID's flag pattern appears most suspicious?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct_letter,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_attack_explanation(stats: dict) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q26/Q29\n",
    "    Which explanation best fits the irregular behavior in this window?\n",
    "    \"\"\"\n",
    "    dom_share = stats.get(\"dominant_share\", 0.0)\n",
    "    gap_mean = stats.get(\"gap_mean\", 0.0)\n",
    "    gap_std = stats.get(\"gap_std\", 0.0)\n",
    "    var = stats.get(\"dominant_payload_var\", 0.0)\n",
    "\n",
    "    if dom_share > 0.7 and gap_mean < FLOODING_THRESHOLD:\n",
    "        correct = \"A\"  # Malicious flooding\n",
    "    elif dom_share > 0.7 and var < 1e-3:\n",
    "        correct = \"A\"  # malicious flooding / fabricated\n",
    "    elif gap_mean > SUPPRESSION_THRESHOLD and gap_std > gap_mean * 0.5:\n",
    "        correct = \"B\"  # Overloaded network or suppression\n",
    "    elif var < 1e-3:\n",
    "        correct = \"C\"  # Legitimate sensor mode change\n",
    "    else:\n",
    "        correct = \"D\"  # Logging artifact / minor anomalies\n",
    "\n",
    "    options = {\n",
    "        \"A\": \"Malicious flooding or fabricated high-rate data.\",\n",
    "        \"B\": \"Overloaded network or suppression-like behavior.\",\n",
    "        \"C\": \"Legitimate mode transition or sensor update burst.\",\n",
    "        \"D\": \"Logging artifact or mild, non-critical anomaly.\",\n",
    "    }\n",
    "    return {\n",
    "        \"type\": \"attack_explanation\",\n",
    "        \"question\": \"Which explanation best fits the irregular behavior in this window?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_analysis_method(stats: dict) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Q31\n",
    "    Which type of analysis would be most appropriate for this window?\n",
    "    \"\"\"\n",
    "    dom_share = stats.get(\"dominant_share\", 0.0)\n",
    "    gap_std = stats.get(\"gap_std\", 0.0)\n",
    "    gap_mean = stats.get(\"gap_mean\", 0.0)\n",
    "    var = stats.get(\"dominant_payload_var\", 0.0)\n",
    "\n",
    "    has_timing_issue = gap_std > gap_mean * 0.5 and gap_mean > 0\n",
    "    has_payload_issue = var > 1.0 or var < 1e-3\n",
    "    has_id_issue = dom_share > 0.5\n",
    "\n",
    "    if has_timing_issue and has_payload_issue and has_id_issue:\n",
    "        correct = \"D\"  # All of the above\n",
    "    elif has_timing_issue:\n",
    "        correct = \"A\"\n",
    "    elif has_payload_issue:\n",
    "        correct = \"B\"\n",
    "    elif has_id_issue:\n",
    "        correct = \"C\"\n",
    "    else:\n",
    "        correct = \"D\" \n",
    "\n",
    "    options = {\n",
    "        \"A\": \"Temporal anomaly detection.\",\n",
    "        \"B\": \"Payload entropy or pattern analysis.\",\n",
    "        \"C\": \"ID frequency and distribution monitoring.\",\n",
    "        \"D\": \"All of the above.\",\n",
    "    }\n",
    "    return {\n",
    "        \"type\": \"analysis_method\",\n",
    "        \"question\": \"Which type of analysis would be most appropriate for this window?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ec616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Optional: enrich profiles with global baseline ID rates ====\n",
    "# Run once after datasets, profiles are created.\n",
    "for name, df_full in datasets.items():\n",
    "    id_counts_full = df_full[\"ID\"].value_counts()\n",
    "    total_full = len(df_full)\n",
    "    baseline = {int(i): float(c / total_full) for i, c in id_counts_full.items()}\n",
    "    profiles[name][\"baseline_id_rate\"] = baseline\n",
    "\n",
    "\n",
    "# ==== Extra MCQ templates ====\n",
    "def generate_mcq_spoofing_suspect_id(df: pd.DataFrame,\n",
    "                                     profile: dict,\n",
    "                                     rng: np.random.Generator) -> Optional[dict]:\n",
    "    expected_ids: Set[int] = profile.get(\"expected_ids\", set())\n",
    "    id_counts = df[\"ID\"].value_counts()\n",
    "    if id_counts.empty:\n",
    "        return None\n",
    "\n",
    "    novel_ids = [int(i) for i in id_counts.index if int(i) not in expected_ids]\n",
    "    if not novel_ids:\n",
    "        # No clear spoofing candidate\n",
    "        letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "        options = {\n",
    "            \"A\": \"The ID with the most irregular timing.\",\n",
    "            \"B\": \"The ID with the largest DLC.\",\n",
    "            \"C\": \"The ID that appears only once.\",\n",
    "            \"D\": \"No ID shows clear spoofing behavior.\",\n",
    "        }\n",
    "        return {\n",
    "            \"type\": \"spoofing_suspect_id\",\n",
    "            \"question\": \"Which ID most likely indicates a spoofing attempt?\",\n",
    "            \"options\": options,\n",
    "            \"answer\": \"D\",\n",
    "        }\n",
    "\n",
    "    # Pick the most frequent novel ID as spoofing candidate\n",
    "    novel_counts = id_counts.loc[[i for i in id_counts.index if int(i) in novel_ids]]\n",
    "    correct_id = int(novel_counts.idxmax())\n",
    "\n",
    "    other_novel = [i for i in novel_ids if i != correct_id]\n",
    "    rng.shuffle(other_novel)\n",
    "    ids_for_options = [correct_id] + other_novel[:2]\n",
    "    ids_for_options = ids_for_options[:3]\n",
    "\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    options = {}\n",
    "    correct_letter = None\n",
    "    for i, id_val in enumerate(ids_for_options):\n",
    "        options[letters[i]] = f\"ID 0x{id_val:03X}\"\n",
    "        if id_val == correct_id:\n",
    "            correct_letter = letters[i]\n",
    "    options[letters[3]] = \"No ID shows clear spoofing behavior.\"\n",
    "\n",
    "    if correct_letter is None:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"type\": \"spoofing_suspect_id\",\n",
    "        \"question\": \"Which ID most likely indicates a spoofing attempt?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct_letter,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_fabricated_payload_id(df: pd.DataFrame,\n",
    "                                       rng: np.random.Generator) -> Optional[dict]:\n",
    "    candidate_ids = []\n",
    "    for id_val, group in df.groupby(\"ID\"):\n",
    "        if len(group) < 3:\n",
    "            continue\n",
    "        payload = group[BYTE_COLUMNS].to_numpy()\n",
    "        var = payload.var()\n",
    "        if var < 1e-3:\n",
    "            candidate_ids.append(int(id_val))\n",
    "\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    options = {}\n",
    "\n",
    "    if not candidate_ids:\n",
    "        options[\"A\"] = \"The ID with repetitive identical frames.\"\n",
    "        options[\"B\"] = \"The ID with the largest DLC.\"\n",
    "        options[\"C\"] = \"The ID that appears very rarely.\"\n",
    "        options[\"D\"] = \"None of the IDs shows fabricated data.\"\n",
    "        return {\n",
    "            \"type\": \"fabricated_payload_id\",\n",
    "            \"question\": \"Which ID's payload most likely suggests fabricated sensor data?\",\n",
    "            \"options\": options,\n",
    "            \"answer\": \"D\",\n",
    "        }\n",
    "\n",
    "    correct_id = rng.choice(candidate_ids)\n",
    "    options[\"A\"] = f\"ID 0x{int(correct_id):03X}\"\n",
    "    other_ids = [int(x) for x in df[\"ID\"].unique() if int(x) != correct_id]\n",
    "    rng.shuffle(other_ids)\n",
    "    idx = 1\n",
    "    for id_val in other_ids[:2]:\n",
    "        options[letters[idx]] = f\"ID 0x{id_val:03X}\"\n",
    "        idx += 1\n",
    "    options[letters[idx]] = \"None of the IDs shows fabricated data.\"\n",
    "\n",
    "    return {\n",
    "        \"type\": \"fabricated_payload_id\",\n",
    "        \"question\": \"Which ID's payload most likely suggests fabricated sensor data?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": \"A\",\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mcq_all_zero_payload_anomaly(df: pd.DataFrame) -> Optional[dict]:\n",
    "    if not BYTE_COLUMNS:\n",
    "        return None\n",
    "    bytes_mat = df[BYTE_COLUMNS].to_numpy()\n",
    "    if bytes_mat.size == 0:\n",
    "        return None\n",
    "\n",
    "    all_zero_mask = (bytes_mat == 0).all(axis=1)\n",
    "    zero_share = all_zero_mask.mean()\n",
    "\n",
    "    if zero_share > 0.3:\n",
    "        correct = \"A\"\n",
    "    else:\n",
    "        correct = \"D\"\n",
    "\n",
    "    options = {\n",
    "        \"A\": \"Uninitialized or placeholder sensor data.\",\n",
    "        \"B\": \"Normal control frames under light load.\",\n",
    "        \"C\": \"Overloaded network with random drops.\",\n",
    "        \"D\": \"Legitimate control frames with diverse payloads.\",\n",
    "    }\n",
    "    return {\n",
    "        \"type\": \"all_zero_payload_anomaly\",\n",
    "        \"question\": \"Which type of anomaly is most consistent with constant all-zero payloads?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": correct,\n",
    "    }\n",
    "\n",
    "for name, df_full in datasets.items():\n",
    "    id_counts_full = df_full[\"ID\"].value_counts()\n",
    "    total_full = len(df_full)\n",
    "    baseline = {int(i): float(c / total_full) for i, c in id_counts_full.items()}\n",
    "    profiles[name][\"baseline_id_rate\"] = baseline\n",
    "\n",
    "def generate_mcq_expected_id_lower_rate(df: pd.DataFrame,\n",
    "                                        profile: dict,\n",
    "                                        rng: np.random.Generator) -> Optional[dict]:\n",
    "    expected_ids: Set[int] = profile.get(\"expected_ids\", set())\n",
    "    baseline: Dict[int, float] = profile.get(\"baseline_id_rate\", {})\n",
    "    if not expected_ids or not baseline:\n",
    "        return None\n",
    "\n",
    "    id_counts = df[\"ID\"].value_counts()\n",
    "    total = len(df)\n",
    "    if total == 0:\n",
    "        return None\n",
    "\n",
    "    ratios = {}\n",
    "    for eid in expected_ids:\n",
    "        base = baseline.get(int(eid), 0.0)\n",
    "        window_count = float(id_counts.get(int(eid), 0.0))\n",
    "        window_rate = window_count / total\n",
    "        if base <= 0:\n",
    "            continue\n",
    "        ratio = window_rate / base\n",
    "        ratios[int(eid)] = ratio\n",
    "\n",
    "    if not ratios:\n",
    "        return None\n",
    "\n",
    "    low_ids = [eid for eid, r in ratios.items() if r < 0.5]\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "    if not low_ids:\n",
    "        options = {\n",
    "            \"A\": \"ID 0x000\",\n",
    "            \"B\": \"ID 0x001\",\n",
    "            \"C\": \"ID 0x002\",\n",
    "            \"D\": \"No deviation observed.\",\n",
    "        }\n",
    "        return {\n",
    "            \"type\": \"expected_id_lower_rate\",\n",
    "            \"question\": \"Which expected ID appears at a lower rate than normal?\",\n",
    "            \"options\": options,\n",
    "            \"answer\": \"D\",\n",
    "        }\n",
    "\n",
    "    sorted_ids = sorted(ratios.items(), key=lambda x: x[1])\n",
    "    correct_id = sorted_ids[0][0]\n",
    "\n",
    "    other_ids = [eid for eid, _ in sorted_ids[1:]]\n",
    "    ids_for_options = [correct_id]\n",
    "    rng.shuffle(other_ids)\n",
    "    ids_for_options.extend(other_ids[:2])\n",
    "    ids_for_options = ids_for_options[:3]\n",
    "\n",
    "    options = {}\n",
    "    options[\"A\"] = f\"ID 0x{int(correct_id):03X}\"\n",
    "    idx = 1\n",
    "    for eid in ids_for_options[1:]:\n",
    "        options[letters[idx]] = f\"ID 0x{int(eid):03X}\"\n",
    "        idx += 1\n",
    "    options[letters[idx]] = \"No deviation observed.\"\n",
    "\n",
    "    return {\n",
    "        \"type\": \"expected_id_lower_rate\",\n",
    "        \"question\": \"Which expected ID appears at a lower rate than normal?\",\n",
    "        \"options\": options,\n",
    "        \"answer\": \"A\",\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_mcq_options_inplace(mcq: dict,\n",
    "                                rng: np.random.Generator) -> dict:\n",
    "    \"\"\"\n",
    "    mcq framework\n",
    "      {\n",
    "        \"question\": ...,\n",
    "        \"options\": {\"A\": \"...\", \"B\": \"...\", \"C\": \"...\", \"D\": \"...\"},\n",
    "        \"answer\": \"B\",\n",
    "        ...\n",
    "      }\n",
    "    \"\"\"\n",
    "    options = mcq.get(\"options\")\n",
    "    answer = mcq.get(\"answer\")\n",
    "\n",
    "    if not options or answer not in options:\n",
    "        return mcq\n",
    "\n",
    "    correct_text = options[answer]\n",
    "    texts = list(options.values())\n",
    "    if len(texts) <= 1:\n",
    "        return mcq\n",
    "\n",
    "    rng.shuffle(texts)\n",
    "\n",
    "    letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    new_options = {}\n",
    "    new_answer = None\n",
    "    for i, text in enumerate(texts):\n",
    "        letter = letters[i]\n",
    "        new_options[letter] = text\n",
    "        if text == correct_text:\n",
    "            new_answer = letter\n",
    "\n",
    "    mcq[\"options\"] = new_options\n",
    "    if new_answer is not None:\n",
    "        mcq[\"answer\"] = new_answer\n",
    "\n",
    "    return mcq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55053fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mcq_for_window(df: pd.DataFrame, profile: dict, rng: np.random.Generator) -> List[dict]:\n",
    "    stats = compute_basic_stats(df)\n",
    "    mcqs: List[dict] = []\n",
    "\n",
    "    # Existing templates (already defined earlier in the notebook)\n",
    "    mcq_attack = generate_mcq_attack_type(stats, profile, rng)\n",
    "    if mcq_attack:\n",
    "        mcqs.append(mcq_attack)\n",
    "\n",
    "    mcq_dom = generate_mcq_dominant_id(df, stats, rng)\n",
    "    if mcq_dom:\n",
    "        mcqs.append(mcq_dom)\n",
    "\n",
    "    mcq_abn = generate_mcq_abnormal_rate_id(stats, rng)\n",
    "    if mcq_abn:\n",
    "        mcqs.append(mcq_abn)\n",
    "\n",
    "    mcq_missing = generate_mcq_missing_expected_id(df, profile, rng)\n",
    "    if mcq_missing:\n",
    "        mcqs.append(mcq_missing)\n",
    "\n",
    "    mcq_time = generate_mcq_timing(stats)\n",
    "    if mcq_time:\n",
    "        mcqs.append(mcq_time)\n",
    "\n",
    "    mcq_const = generate_mcq_constant_payload_id(df, rng)\n",
    "    if mcq_const:\n",
    "        mcqs.append(mcq_const)\n",
    "\n",
    "    mcq_payload = generate_mcq_payload_pattern(stats)\n",
    "    if mcq_payload:\n",
    "        mcqs.append(mcq_payload)\n",
    "\n",
    "    mcq_dlc = generate_mcq_dlc_distribution(df)\n",
    "    if mcq_dlc:\n",
    "        mcqs.append(mcq_dlc)\n",
    "\n",
    "    mcq_flag = generate_mcq_flag_behavior(df)\n",
    "    if mcq_flag:\n",
    "        mcqs.append(mcq_flag)\n",
    "\n",
    "    mcq_overall = generate_mcq_overall_window(stats)\n",
    "    if mcq_overall:\n",
    "        mcqs.append(mcq_overall)\n",
    "\n",
    "    mcq_irreg_id = generate_mcq_id_most_irregular_timing(df, rng)\n",
    "    if mcq_irreg_id:\n",
    "        mcqs.append(mcq_irreg_id)\n",
    "\n",
    "    mcq_shortest_gap = generate_mcq_id_shortest_gap(df, rng)\n",
    "    if mcq_shortest_gap:\n",
    "        mcqs.append(mcq_shortest_gap)\n",
    "\n",
    "    mcq_win_dur = generate_mcq_window_duration(stats)\n",
    "    if mcq_win_dur:\n",
    "        mcqs.append(mcq_win_dur)\n",
    "\n",
    "    mcq_burst = generate_mcq_burst_explanation(stats)\n",
    "    if mcq_burst:\n",
    "        mcqs.append(mcq_burst)\n",
    "\n",
    "    mcq_high_dlc_id = generate_mcq_high_dlc_id(df, rng)\n",
    "    if mcq_high_dlc_id:\n",
    "        mcqs.append(mcq_high_dlc_id)\n",
    "\n",
    "    mcq_high_dlc_inc = generate_mcq_high_dlc_increase(df)\n",
    "    if mcq_high_dlc_inc:\n",
    "        mcqs.append(mcq_high_dlc_inc)\n",
    "\n",
    "    mcq_crit_abn = generate_mcq_critical_id_abnormal(df, profile, rng)\n",
    "    if mcq_crit_abn:\n",
    "        mcqs.append(mcq_crit_abn)\n",
    "\n",
    "    mcq_flag_susp = generate_mcq_flag_suspicious_id(df, rng)\n",
    "    if mcq_flag_susp:\n",
    "        mcqs.append(mcq_flag_susp)\n",
    "\n",
    "    mcq_att_expl = generate_mcq_attack_explanation(stats)\n",
    "    if mcq_att_expl:\n",
    "        mcqs.append(mcq_att_expl)\n",
    "\n",
    "    mcq_analysis = generate_mcq_analysis_method(stats)\n",
    "    if mcq_analysis:\n",
    "        mcqs.append(mcq_analysis)\n",
    "\n",
    "    mcq_spoof_id = generate_mcq_spoofing_suspect_id(df, profile, rng)\n",
    "    if mcq_spoof_id:\n",
    "        mcqs.append(mcq_spoof_id)\n",
    "\n",
    "    mcq_fab_id = generate_mcq_fabricated_payload_id(df, rng)\n",
    "    if mcq_fab_id:\n",
    "        mcqs.append(mcq_fab_id)\n",
    "\n",
    "    mcq_zero_anom = generate_mcq_all_zero_payload_anomaly(df)\n",
    "    if mcq_zero_anom:\n",
    "        mcqs.append(mcq_zero_anom)\n",
    "\n",
    "    mcq_exp_low = generate_mcq_expected_id_lower_rate(df, profile, rng)\n",
    "    if mcq_exp_low:\n",
    "        mcqs.append(mcq_exp_low)\n",
    "\n",
    "    # Limit per-window MCQs\n",
    "    if len(mcqs) > MCQS_PER_WINDOW:\n",
    "        idxs = rng.choice(len(mcqs), size=MCQS_PER_WINDOW, replace=False)\n",
    "        mcqs = [mcqs[i] for i in idxs]\n",
    "\n",
    "    for mcq in mcqs:\n",
    "        shuffle_mcq_options_inplace(mcq, rng)\n",
    "        \n",
    "    return mcqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da47d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Generating MCQ questions for DoS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DoS windows: 100%|| 1832/1832 [00:50<00:00, 36.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] DoS: saved 5496 MCQ questions -> DoS_tf_qa/dos_mcq_questions.jsonl, DoS_tf_qa/dos_mcq_questions.json\n",
      "[INFO] Generating MCQ questions for Fuzzy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fuzzy windows: 100%|| 1919/1919 [00:59<00:00, 32.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fuzzy: saved 5757 MCQ questions -> Fuzzy_tf_qa/fuzzy_mcq_questions.jsonl, Fuzzy_tf_qa/fuzzy_mcq_questions.json\n",
      "[INFO] Generating MCQ questions for Gear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gear windows: 100%|| 2221/2221 [01:02<00:00, 35.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Gear: saved 6663 MCQ questions -> Gear_tf_qa/gear_mcq_questions.jsonl, Gear_tf_qa/gear_mcq_questions.json\n",
      "[INFO] Generating MCQ questions for RPM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPM windows: 100%|| 2310/2310 [01:05<00:00, 35.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] RPM: saved 6930 MCQ questions -> RPM_tf_qa/rpm_mcq_questions.jsonl, RPM_tf_qa/rpm_mcq_questions.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: main loop  per-dataset question generation\n",
    "for ds_idx, (name, df) in enumerate(datasets.items()):\n",
    "    print(f\"[INFO] Generating MCQ questions for {name}\")\n",
    "    starts = iter_window_starts(len(df))\n",
    "    sampled_starts = sample_window_indices(starts, rng_global)\n",
    "\n",
    "    out_dir = Path(f\"{name}_mcq_qa\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ql_path = out_dir / f\"{name.lower()}_mcq_questions.jsonl\"\n",
    "    qj_path = out_dir / f\"{name.lower()}_mcq_questions.json\"\n",
    "\n",
    "    ql_path.write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "    qa_id_counter = 0\n",
    "    records_all = []\n",
    "\n",
    "    with ql_path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        for window_idx, start in enumerate(tqdm(sampled_starts, desc=f\"{name} windows\")):\n",
    "            window = df.iloc[start:start + WINDOW_SIZE].copy().reset_index(drop=True)\n",
    "            mcq_items = generate_mcq_for_window(window, profiles[name], rng_global)\n",
    "            if not mcq_items:\n",
    "                continue\n",
    "\n",
    "            context = format_window(window)\n",
    "            for local_q_idx, mcq in enumerate(mcq_items):\n",
    "                qa_id = f\"{name}_MCQ_{window_idx:06d}_{local_q_idx:02d}\"\n",
    "                record = {\n",
    "                    \"qa_id\": qa_id,\n",
    "                    \"metadata\": {\n",
    "                        \"dataset\": name,\n",
    "                        \"window_index\": int(window_idx),\n",
    "                        \"window_start\": int(start),\n",
    "                        \"window_size\": int(WINDOW_SIZE),\n",
    "                    },\n",
    "                    \"context\": context,\n",
    "                    \"mcq_type\": mcq[\"type\"],\n",
    "                    \"question\": mcq[\"question\"],\n",
    "                    \"options\": mcq[\"options\"],\n",
    "                    \"answer\": mcq[\"answer\"], \n",
    "                }\n",
    "                f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "                records_all.append(record)\n",
    "                qa_id_counter += 1\n",
    "\n",
    "    with qj_path.open(\"w\", encoding=\"utf-8\") as jf:\n",
    "        json.dump(records_all, jf, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"[INFO] {name}: saved {qa_id_counter} MCQ questions -> {ql_path}, {qj_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
